{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ed84ac-4e39-4677-acf5-268cc23c811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 1) SETUP ==========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- I/O (adjust paths if needed) ---\n",
    "dividend_df = pd.read_csv(\"Dividend_Dataset.csv\", parse_dates=[\"Announcement_Date\"])\n",
    "returns_df  = pd.read_csv(\"Merged_Data.csv\",    parse_dates=[\"Date\"])\n",
    "\n",
    "# Expected columns:\n",
    "# dividend_df: Announcement_Date, Ticker, [Dividend_Type, Dividend_Amount, Company_Name, ...]\n",
    "# returns_df : Date, Ticker, Stock_Returns, Market_Returns\n",
    "\n",
    "# --- Parameters (trading-day based) ---\n",
    "EST_LENGTH    = 110   # use exactly 110 clean obs\n",
    "BUFFER_LENGTH = 10    # buffer right before event (excluded from estimation)\n",
    "EVENT_K       = 5     # event window [-5, +5]\n",
    "\n",
    "# --- Safety: types, sort, dedupe events ---\n",
    "returns_df[\"Date\"] = pd.to_datetime(returns_df[\"Date\"])\n",
    "dividend_df[\"Announcement_Date\"] = pd.to_datetime(dividend_df[\"Announcement_Date\"])\n",
    "returns_df = returns_df.sort_values([\"Ticker\",\"Date\"]).reset_index(drop=True)\n",
    "dividend_df = (dividend_df\n",
    "               .sort_values([\"Ticker\",\"Announcement_Date\"])\n",
    "               .drop_duplicates(subset=[\"Ticker\",\"Announcement_Date\"])\n",
    "               .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac2bc3f-47e4-47a9-9186-a04fdd1c8e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated alphas/betas for 702 events (dropped in estimation: 58).\n",
      "Saved: alpha_beta_by_event.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== 2) ESTIMATION ONLY (STRICT) ==========\n",
    "alpha_beta_rows = []\n",
    "drop_rows_est = []\n",
    "\n",
    "def log_drop_est(ticker, D, reason, detail=None):\n",
    "    drop_rows_est.append({\n",
    "        \"Ticker\": ticker,\n",
    "        \"Event_Date\": pd.to_datetime(D),\n",
    "        \"Reason\": reason,\n",
    "        \"Detail\": detail\n",
    "    })\n",
    "\n",
    "need = EST_LENGTH + BUFFER_LENGTH\n",
    "\n",
    "for _, ev in dividend_df[[\"Ticker\",\"Announcement_Date\"]].dropna().iterrows():\n",
    "    ticker = ev[\"Ticker\"]; D = ev[\"Announcement_Date\"]\n",
    "    firm = returns_df[returns_df[\"Ticker\"] == ticker]\n",
    "    if firm.empty:\n",
    "        log_drop_est(ticker, D, \"no_returns_for_ticker\")\n",
    "        continue\n",
    "\n",
    "    pre_all = firm[firm[\"Date\"] < D]\n",
    "    if pre_all.shape[0] < need:\n",
    "        log_drop_est(ticker, D, \"insufficient_pre_event_history\",\n",
    "                     detail=f\"Have {pre_all.shape[0]} < required {need}\")\n",
    "        continue\n",
    "\n",
    "    pre = pre_all.tail(need).reset_index(drop=True)\n",
    "    est = pre.iloc[:EST_LENGTH].copy()\n",
    "\n",
    "    Ri = est[\"Stock_Returns\"].to_numpy()\n",
    "    Rm = est[\"Market_Returns\"].to_numpy()\n",
    "\n",
    "    # STRICT: must be completely clean\n",
    "    if np.isnan(Ri).any() or np.isnan(Rm).any():\n",
    "        log_drop_est(ticker, D, \"nan_in_estimation_window\",\n",
    "                     detail=f\"NaNs -> Stock_Returns:{int(np.isnan(Ri).sum())}, Market_Returns:{int(np.isnan(Rm).sum())}\")\n",
    "        continue\n",
    "\n",
    "    var_m = np.var(Rm, ddof=1)\n",
    "    if (not np.isfinite(var_m)) or (var_m == 0):\n",
    "        log_drop_est(ticker, D, \"zero_or_nan_market_variance_in_estimation_window\",\n",
    "                     detail=f\"var_m={var_m}\")\n",
    "        continue\n",
    "\n",
    "    cov_im = np.cov(Ri, Rm, ddof=1)[0, 1]\n",
    "    beta  = cov_im / var_m\n",
    "    alpha = Ri.mean() - beta * Rm.mean()\n",
    "\n",
    "    # Optional R2\n",
    "    fitted = alpha + beta * Rm\n",
    "    ss_tot = np.sum((Ri - Ri.mean())**2)\n",
    "    ss_res = np.sum((Ri - fitted)**2)\n",
    "    R2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "\n",
    "    alpha_beta_rows.append({\n",
    "        \"Ticker\": ticker,\n",
    "        \"Event_Date\": D,\n",
    "        \"Alpha\": float(alpha),\n",
    "        \"Beta\": float(beta),\n",
    "        \"R2_optional\": float(R2) if np.isfinite(R2) else np.nan,\n",
    "        \"Estimation_Obs\": EST_LENGTH\n",
    "    })\n",
    "\n",
    "alpha_beta_df = pd.DataFrame(alpha_beta_rows).sort_values([\"Ticker\",\"Event_Date\"]).reset_index(drop=True)\n",
    "drop_log_est  = pd.DataFrame(drop_rows_est).sort_values([\"Event_Date\",\"Ticker\"]).reset_index(drop=True)\n",
    "\n",
    "# --- Save αβ estimates (requested) ---\n",
    "alpha_beta_df.to_csv(\"alpha_beta_by_event.csv\", index=False)\n",
    "\n",
    "print(f\"Estimated alphas/betas for {alpha_beta_df.shape[0]} events \"\n",
    "      f\"(dropped in estimation: {drop_log_est.shape[0]}).\")\n",
    "print(\"Saved: alpha_beta_by_event.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656591ec-9512-418c-8fce-c88153991c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Event_Date</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>R2_optional</th>\n",
       "      <th>Estimation_Obs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2016-03-09</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>1.934967</td>\n",
       "      <td>0.371993</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>1.355969</td>\n",
       "      <td>0.051619</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2018-05-10</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>2.711392</td>\n",
       "      <td>0.334825</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>-0.002520</td>\n",
       "      <td>1.776056</td>\n",
       "      <td>0.210455</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADANIENT.NS</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>1.457345</td>\n",
       "      <td>0.363193</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>2022-03-25</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.951547</td>\n",
       "      <td>0.367928</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>1.042780</td>\n",
       "      <td>0.425205</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>1.289917</td>\n",
       "      <td>0.316941</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>2025-01-17</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>1.184604</td>\n",
       "      <td>0.374806</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>WIPRO.NS</td>\n",
       "      <td>2025-07-17</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>1.304249</td>\n",
       "      <td>0.301366</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>702 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Ticker Event_Date     Alpha      Beta  R2_optional  Estimation_Obs\n",
       "0    ADANIENT.NS 2016-03-09 -0.000245  1.934967     0.371993             110\n",
       "1    ADANIENT.NS 2017-05-24  0.004341  1.355969     0.051619             110\n",
       "2    ADANIENT.NS 2018-05-10  0.000159  2.711392     0.334825             110\n",
       "3    ADANIENT.NS 2019-05-29 -0.002520  1.776056     0.210455             110\n",
       "4    ADANIENT.NS 2020-03-12  0.004043  1.457345     0.363193             110\n",
       "..           ...        ...       ...       ...          ...             ...\n",
       "697     WIPRO.NS 2022-03-25 -0.000004  0.951547     0.367928             110\n",
       "698     WIPRO.NS 2023-01-13 -0.001342  1.042780     0.425205             110\n",
       "699     WIPRO.NS 2024-01-12 -0.000001  1.289917     0.316941             110\n",
       "700     WIPRO.NS 2025-01-17  0.001834  1.184604     0.374806             110\n",
       "701     WIPRO.NS 2025-07-17  0.001453  1.304249     0.301366             110\n",
       "\n",
       "[702 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_beta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "377775c1-e89d-4208-a66f-24b8bb5b8084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built symmetric panel for [-5, +5] with 7183 rows across 653 events.\n",
      "\n",
      "AAR table (pooled by event day):\n",
      " Event_Day_Index  Number_of_Events  Average_Abnormal_Return  Standard_Deviation  Standard_Error  t_statistic\n",
      "              -5               653                -0.000358            0.016632        0.000651    -0.550451\n",
      "              -4               653                 0.000642            0.016596        0.000649     0.988550\n",
      "              -3               653                 0.000163            0.015608        0.000611     0.267362\n",
      "              -2               653                 0.000010            0.015567        0.000609     0.016326\n",
      "              -1               653                -0.000391            0.017445        0.000683    -0.573344\n",
      "               0               653                 0.000834            0.021052        0.000824     1.012865\n",
      "               1               653                -0.000276            0.029670        0.001161    -0.237695\n",
      "               2               653                 0.000725            0.018007        0.000705     1.028892\n",
      "               3               653                 0.001232            0.016063        0.000629     1.960473\n",
      "               4               653                -0.000205            0.015783        0.000618    -0.331171\n",
      "               5               653                -0.000718            0.014913        0.000584    -1.230240\n",
      "\n",
      "CAAR summary for [-5, +5] window:\n",
      " Number_of_Events  CAAR_from_AAR_Sum  CAAR_from_Mean_of_CARs  Standard_Deviation_of_CARs  Standard_Error_of_CARs  t_statistic_for_Mean_CAR\n",
      "              653           0.001659                0.001659                    0.063451                0.002483                  0.668107\n",
      "\n",
      "MERGING CAR WITH DIVIDEND DATA\n",
      "========================================\n",
      "CAR events: 653\n",
      "Merged events: 657\n",
      "Events with dividend data: 657\n",
      "Events without dividend data: 0\n",
      "Saved: merged_dividend_car_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ========== 3) EVENT WINDOW + AAR/CAAR (same format as before; no significance flags) ==========\n",
    "\n",
    "panel_rows = []\n",
    "\n",
    "for _, row in alpha_beta_df.iterrows():\n",
    "    ticker = row[\"Ticker\"]\n",
    "    D      = row[\"Event_Date\"]\n",
    "    alpha  = row[\"Alpha\"]\n",
    "    beta   = row[\"Beta\"]\n",
    "\n",
    "    firm = returns_df[returns_df[\"Ticker\"] == ticker]\n",
    "    if firm.empty:\n",
    "        continue\n",
    "\n",
    "    # K trading days before (strictly < D) and 0..+K (>= D)\n",
    "    preK  = firm[firm[\"Date\"] < D].tail(EVENT_K)\n",
    "    postK = firm[firm[\"Date\"] >= D].head(EVENT_K + 1)\n",
    "\n",
    "    # Require exact coverage\n",
    "    if (len(preK) < EVENT_K) or (len(postK) < (EVENT_K + 1)):\n",
    "        continue\n",
    "\n",
    "    preK  = preK.sort_values(\"Date\").assign(event_day_index=np.arange(-EVENT_K, 0, 1))\n",
    "    postK = postK.sort_values(\"Date\").assign(event_day_index=np.arange(0, EVENT_K + 1, 1))\n",
    "    window = pd.concat([preK, postK], ignore_index=True)\n",
    "\n",
    "    # Expected & abnormal returns (Market Model)\n",
    "    expected = alpha + beta * window[\"Market_Returns\"].to_numpy()\n",
    "    AR       = window[\"Stock_Returns\"].to_numpy() - expected\n",
    "\n",
    "    panel_rows.append(pd.DataFrame({\n",
    "        \"Ticker\": ticker,\n",
    "        \"event_date\": D,\n",
    "        \"trading_date\": window[\"Date\"].to_numpy(),\n",
    "        \"event_day_index\": window[\"event_day_index\"].to_numpy(),\n",
    "        \"Market_Return\": window[\"Market_Returns\"].to_numpy(),\n",
    "        \"Stock_Return\": window[\"Stock_Returns\"].to_numpy(),\n",
    "        \"Expected_Return\": expected,\n",
    "        \"Abnormal_Return\": AR\n",
    "    }))\n",
    "\n",
    "sym_panel = (\n",
    "    pd.concat(panel_rows, ignore_index=True)\n",
    "    if panel_rows else\n",
    "    pd.DataFrame(columns=[\n",
    "        \"Ticker\",\"event_date\",\"trading_date\",\"event_day_index\",\n",
    "        \"Market_Return\",\"Stock_Return\",\"Expected_Return\",\"Abnormal_Return\"\n",
    "    ])\n",
    ")\n",
    "\n",
    "# ---------- AAR (per event day) ----------\n",
    "if sym_panel.empty:\n",
    "    aar_table = pd.DataFrame(columns=[\n",
    "        \"Event_Day_Index\",\"Number_of_Events\",\"Average_Abnormal_Return\",\n",
    "        \"Standard_Deviation\",\"Standard_Error\",\"t_statistic\"\n",
    "    ])\n",
    "else:\n",
    "    aar = (\n",
    "        sym_panel.groupby(\"event_day_index\")[\"Abnormal_Return\"]\n",
    "                 .agg(Number_of_Events=\"count\",\n",
    "                      Average_Abnormal_Return=\"mean\",\n",
    "                      Standard_Deviation=lambda x: x.std(ddof=1))\n",
    "                 .reset_index()\n",
    "                 .sort_values(\"event_day_index\")\n",
    "    )\n",
    "    aar[\"Standard_Error\"] = aar[\"Standard_Deviation\"] / np.sqrt(aar[\"Number_of_Events\"])\n",
    "    aar[\"t_statistic\"]    = aar[\"Average_Abnormal_Return\"] / aar[\"Standard_Error\"]\n",
    "    aar_table = aar.rename(columns={\"event_day_index\": \"Event_Day_Index\"})\n",
    "\n",
    "# ---------- CAAR over [-K, +K] ----------\n",
    "if sym_panel.empty:\n",
    "    caar_summary = pd.DataFrame([{\n",
    "        \"Number_of_Events\": 0,\n",
    "        \"CAAR_from_AAR_Sum\": np.nan,\n",
    "        \"CAAR_from_Mean_of_CARs\": np.nan,\n",
    "        \"Standard_Deviation_of_CARs\": np.nan,\n",
    "        \"Standard_Error_of_CARs\": np.nan,\n",
    "        \"t_statistic_for_Mean_CAR\": np.nan\n",
    "    }])\n",
    "    car_by_event = pd.DataFrame(columns=[\"Ticker\",\"event_date\",\"CAR\"])\n",
    "else:\n",
    "    caar_from_aar = float(aar_table[\"Average_Abnormal_Return\"].sum())\n",
    "    car_by_event = (\n",
    "        sym_panel.groupby([\"Ticker\",\"event_date\"], as_index=False)\n",
    "                 .agg(CAR=(\"Abnormal_Return\",\"sum\"))\n",
    "                 .sort_values([\"Ticker\",\"event_date\"])\n",
    "    )\n",
    "    N_ev   = car_by_event.shape[0]\n",
    "    caar_mean = float(car_by_event[\"CAR\"].mean()) if N_ev > 0 else np.nan\n",
    "    caar_sd   = float(car_by_event[\"CAR\"].std(ddof=1)) if N_ev > 1 else np.nan\n",
    "    caar_se   = (caar_sd / np.sqrt(N_ev)) if N_ev > 1 else np.nan\n",
    "    caar_t    = (caar_mean / caar_se) if (isinstance(caar_se, float) and caar_se > 0) else np.nan\n",
    "\n",
    "    caar_summary = pd.DataFrame([{\n",
    "        \"Number_of_Events\": N_ev,\n",
    "        \"CAAR_from_AAR_Sum\": caar_from_aar,\n",
    "        \"CAAR_from_Mean_of_CARs\": caar_mean,\n",
    "        \"Standard_Deviation_of_CARs\": caar_sd,\n",
    "        \"Standard_Error_of_CARs\": caar_se,\n",
    "        \"t_statistic_for_Mean_CAR\": caar_t\n",
    "    }])\n",
    "\n",
    "# ---------- OUTPUT (same style as your earlier printout) ----------\n",
    "n_kept = sym_panel[[\"Ticker\",\"event_date\"]].drop_duplicates().shape[0] if not sym_panel.empty else 0\n",
    "print(f\"Built symmetric panel for [-{EVENT_K}, +{EVENT_K}] with {len(sym_panel)} rows across {n_kept} events.\")\n",
    "\n",
    "print(\"\\nAAR table (pooled by event day):\")\n",
    "print(aar_table.to_string(index=False))\n",
    "\n",
    "print(\"\\nCAAR summary for [-{0}, +{0}] window:\".format(EVENT_K))\n",
    "print(caar_summary.to_string(index=False))\n",
    "\n",
    "# ---------- SAVE EXTRA CSVs (but don't print contents) ----------\n",
    "#sym_panel.to_csv(f\"AR_panel_[-{EVENT_K},+{EVENT_K}].csv\", index=False)\n",
    "#aar_table.to_csv(f\"AAR_table_[-{EVENT_K},+{EVENT_K}].csv\", index=False)\n",
    "#caar_summary.to_csv(f\"CAAR_summary_[-{EVENT_K},+{EVENT_K}].csv\", index=False)\n",
    "car_by_event.to_csv(f\"CAR_by_event.csv\", index=False)\n",
    "\n",
    "# ========== MERGE CAR WITH DIVIDEND DATA ==========\n",
    "print(\"\\nMERGING CAR WITH DIVIDEND DATA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load the dividend dataset \n",
    "dividend_df = pd.read_csv(\"Dividend_Dataset.csv\", parse_dates=[\"Announcement_Date\"])\n",
    "car_df = pd.read_csv(\"CAR_by_event.csv\", parse_dates=[\"event_date\"])\n",
    "\n",
    "# Rename and merge\n",
    "car_df = car_df.rename(columns={'event_date': 'Announcement_Date'})\n",
    "merged_df = pd.merge(\n",
    "    car_df,\n",
    "    dividend_df[['Announcement_Date', 'Ticker', 'Dividend_Amount', 'Dividend_Type']],\n",
    "    on=['Announcement_Date', 'Ticker'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename Dividend_Amount to DPS\n",
    "merged_df = merged_df.rename(columns={'Dividend_Amount': 'DPS'})\n",
    "\n",
    "print(f\"CAR events: {len(car_df)}\")\n",
    "print(f\"Merged events: {len(merged_df)}\")\n",
    "print(f\"Events with dividend data: {merged_df['DPS'].notnull().sum()}\")\n",
    "print(f\"Events without dividend data: {merged_df['DPS'].isnull().sum()}\")\n",
    "\n",
    "# Save the merged dataset\n",
    "merged_df.to_csv('merged_dividend_car_data.csv', index=False)\n",
    "print(\"Saved: merged_dividend_car_data.csv\")\n",
    "\n",
    "# ========== NOW CONTINUE WITH PRICE MERGE =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268eaac9-eb73-4f45-b7c9-9da319bb9e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27db2685-e6b0-4079-acc5-7aba88a69358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Ticker Announcement_Date       CAR  DPS Dividend_Type\n",
      "0  ADANIENT.NS        2016-03-09 -0.016032  0.4       Interim\n",
      "1  ADANIENT.NS        2017-05-24 -0.108284  0.4         Final\n",
      "2  ADANIENT.NS        2018-05-10 -0.039030  0.4         Final\n",
      "3  ADANIENT.NS        2019-05-29 -0.000906  0.4         Final\n",
      "4  ADANIENT.NS        2020-03-12 -0.135723  1.0       Interim\n",
      "\n",
      "Merged dataset shape: (657, 5)\n",
      "\n",
      "Columns in merged dataset: ['Ticker', 'Announcement_Date', 'CAR', 'DPS', 'Dividend_Type']\n",
      "\n",
      "Missing values in each column:\n",
      "Ticker               0\n",
      "Announcement_Date    0\n",
      "CAR                  0\n",
      "DPS                  0\n",
      "Dividend_Type        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have both datasets loaded as DataFrames\n",
    "dividend_df = pd.read_csv('Dividend_Dataset.csv')  # or your file path\n",
    "car_df = pd.read_csv('CAR_by_event.csv')           # or your file path\n",
    "\n",
    "# Convert date columns to datetime to ensure proper matching\n",
    "dividend_df['Announcement_Date'] = pd.to_datetime(dividend_df['Announcement_Date'])\n",
    "car_df['event_date'] = pd.to_datetime(car_df['event_date'])\n",
    "\n",
    "# First, rename event_date to Announcement_Date in the car_df\n",
    "car_df = car_df.rename(columns={'event_date': 'Announcement_Date'})\n",
    "\n",
    "# Now merge the datasets\n",
    "merged_df = pd.merge(\n",
    "    car_df,\n",
    "    dividend_df[['Announcement_Date', 'Ticker', 'Dividend_Amount', 'Dividend_Type']],\n",
    "    on=['Announcement_Date', 'Ticker'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename Dividend_Amount to DPS\n",
    "merged_df = merged_df.rename(columns={'Dividend_Amount': 'DPS'})\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(merged_df.head())\n",
    "print(f\"\\nMerged dataset shape: {merged_df.shape}\")\n",
    "print(f\"\\nColumns in merged dataset: {merged_df.columns.tolist()}\")\n",
    "\n",
    "# Check for any missing values in the merged data\n",
    "print(f\"\\nMissing values in each column:\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# If you want to save the merged dataset\n",
    "merged_df.to_csv('merged_dividend_car_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb33068-de3a-47e9-9876-2a4a146874a3",
   "metadata": {},
   "source": [
    "### Dividend_Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26eaa437-1299-4d1a-a713-42192ac11367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame Shape: (657, 8)\n",
      "\n",
      "Columns in final dataset:\n",
      "['Ticker', 'Announcement_Date', 'CAR', 'DPS', 'Dividend_Type', 'Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield']\n",
      "\n",
      "New columns added: Event_Date_AdjClose, Prior_Day_AdjClose, Dividend_Yield\n",
      "\n",
      "First few rows:\n",
      "        Ticker Announcement_Date       CAR  DPS Dividend_Type  \\\n",
      "0  ADANIENT.NS        2016-03-09 -0.016032  0.4       Interim   \n",
      "1  ADANIENT.NS        2017-05-24 -0.108284  0.4         Final   \n",
      "2  ADANIENT.NS        2018-05-10 -0.039030  0.4         Final   \n",
      "3  ADANIENT.NS        2019-05-29 -0.000906  0.4         Final   \n",
      "4  ADANIENT.NS        2020-03-12 -0.135723  1.0       Interim   \n",
      "\n",
      "   Event_Date_AdjClose  Prior_Day_AdjClose  Dividend_Yield  \n",
      "0            35.040146           33.800018        0.011834  \n",
      "1            60.596619           60.356586        0.006627  \n",
      "2            79.972527           81.487999        0.004909  \n",
      "3           153.172226          155.640350        0.002570  \n",
      "4           160.570099          193.842728        0.005159  \n",
      "\n",
      "Missing values in new columns:\n",
      "Event_Date_AdjClose    3\n",
      "Prior_Day_AdjClose     0\n",
      "Dividend_Yield         0\n",
      "dtype: int64\n",
      "\n",
      "Sample verification (showing announcement date and most recent trading date):\n",
      "Ticker: ADANIENT.NS, Announcement: 2016-03-09, Most Recent Trading: 2016-03-08\n",
      "Ticker: ADANIENT.NS, Announcement: 2017-05-24, Most Recent Trading: 2017-05-23\n",
      "Ticker: ADANIENT.NS, Announcement: 2018-05-10, Most Recent Trading: 2018-05-09\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the stock prices dataset\n",
    "prices_df = pd.read_csv('nifty50_stock_prices.csv')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "merged_df['Announcement_Date'] = pd.to_datetime(merged_df['Announcement_Date'])\n",
    "\n",
    "# Create a copy to avoid modifying the original during operations\n",
    "result_df = merged_df.copy()\n",
    "\n",
    "# Get event date's AdjClose price\n",
    "event_prices = prices_df[['Date', 'Ticker', 'AdjClose']].copy()\n",
    "event_prices = event_prices.rename(columns={'AdjClose': 'Event_Date_AdjClose'})\n",
    "\n",
    "result_df = pd.merge(\n",
    "    result_df,\n",
    "    event_prices,\n",
    "    left_on=['Announcement_Date', 'Ticker'],\n",
    "    right_on=['Date', 'Ticker'],\n",
    "    how='left'\n",
    ").drop('Date', axis=1)\n",
    "\n",
    "# Create a dictionary of all available trading dates for each ticker\n",
    "available_dates = {}\n",
    "for ticker in prices_df['Ticker'].unique():\n",
    "    ticker_dates = set(prices_df[prices_df['Ticker'] == ticker]['Date'])\n",
    "    available_dates[ticker] = sorted(ticker_dates)\n",
    "\n",
    "def get_most_recent_trading_price(ticker, announcement_date):\n",
    "    \"\"\"Get the most recent trading day price before announcement date\"\"\"\n",
    "    if ticker not in available_dates:\n",
    "        return None\n",
    "    \n",
    "    # Get all trading dates that are BEFORE the announcement date\n",
    "    prior_dates = [date for date in available_dates[ticker] if date < announcement_date]\n",
    "    \n",
    "    if not prior_dates:\n",
    "        return None\n",
    "    \n",
    "    # Get the most recent trading date\n",
    "    most_recent_date = max(prior_dates)\n",
    "    \n",
    "    # Get the price for that date\n",
    "    return prices_df[(prices_df['Ticker'] == ticker) & \n",
    "                    (prices_df['Date'] == most_recent_date)]['AdjClose'].values[0]\n",
    "\n",
    "# Get previous trading day's AdjClose price\n",
    "result_df['Prior_Day_AdjClose'] = result_df.apply(\n",
    "    lambda row: get_most_recent_trading_price(row['Ticker'], row['Announcement_Date']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calculate Dividend Yield (DPS / Prior Trading Day AdjClose Price)\n",
    "result_df['Dividend_Yield'] = result_df['DPS'] / result_df['Prior_Day_AdjClose']\n",
    "\n",
    "# Display the results\n",
    "print(\"Final DataFrame Shape:\", result_df.shape)\n",
    "print(\"\\nColumns in final dataset:\")\n",
    "print(result_df.columns.tolist())\n",
    "print(f\"\\nNew columns added: Event_Date_AdjClose, Prior_Day_AdjClose, Dividend_Yield\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(result_df.head())\n",
    "\n",
    "# Check for any missing values\n",
    "print(f\"\\nMissing values in new columns:\")\n",
    "print(result_df[['Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield']].isnull().sum())\n",
    "\n",
    "# Show some examples to verify the logic\n",
    "print(\"\\nSample verification (showing announcement date and most recent trading date):\")\n",
    "sample = result_df.head(3).copy()\n",
    "for _, row in sample.iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    ann_date = row['Announcement_Date']\n",
    "    recent_dates = [d for d in available_dates[ticker] if d < ann_date]\n",
    "    most_recent = max(recent_dates) if recent_dates else None\n",
    "    print(f\"Ticker: {ticker}, Announcement: {ann_date.date()}, Most Recent Trading: {most_recent.date() if most_recent else 'None'}\")\n",
    "merged_df.to_csv('merged_dividend_car_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04093a10-ae29-49d8-88bb-843914572109",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('dividend_yield_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae98c83-a87f-4233-9d43-ab4a758434ef",
   "metadata": {},
   "source": [
    "### Dividend_Change_Pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3427d92-7826-4a9d-b441-30d0d64ee366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset created!\n",
      "Columns available:\n",
      "['Ticker', 'Announcement_Date', 'CAR', 'DPS', 'Dividend_Type', 'Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield', 'DPS_Change', 'DPS_Pct_Change', 'Dividend_Direction_Text', 'Dividend_Direction_Num']\n",
      "\n",
      "DPS_Change statistics:\n",
      "count    577.000000\n",
      "mean       1.080364\n",
      "std       18.244433\n",
      "min     -133.000000\n",
      "25%        0.000000\n",
      "50%        0.250000\n",
      "75%        2.400000\n",
      "max      157.000000\n",
      "Name: DPS_Change, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate dividend change for same dividend type\n",
    "result_df['DPS_Change'] = result_df.groupby(['Ticker', 'Dividend_Type'])['DPS'].diff()\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('dividend_yield_analysis_final.csv', index=False)\n",
    "\n",
    "print(\"Final dataset created!\")\n",
    "print(\"Columns available:\")\n",
    "print(result_df.columns.tolist())\n",
    "print(f\"\\nDPS_Change statistics:\")\n",
    "print(result_df['DPS_Change'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69fd831a-767e-4372-9c74-5b03cfeaadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset created!\n",
      "Total rows: 657\n",
      "\n",
      "Columns available:\n",
      "['Ticker', 'Announcement_Date', 'CAR', 'DPS', 'Dividend_Type', 'Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield', 'DPS_Change', 'DPS_Pct_Change', 'Dividend_Direction_Text', 'Dividend_Direction_Num']\n",
      "\n",
      "DPS_Change statistics:\n",
      "count    577.000000\n",
      "mean       1.080364\n",
      "std       18.244433\n",
      "min     -133.000000\n",
      "25%        0.000000\n",
      "50%        0.250000\n",
      "75%        2.400000\n",
      "max      157.000000\n",
      "Name: DPS_Change, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate dividend change for same dividend type\n",
    "result_df['DPS_Change'] = result_df.groupby(['Ticker', 'Dividend_Type'])['DPS'].diff()\n",
    "\n",
    "# Calculate market percentage change (assuming you have a 'Price' column)\n",
    "result_df['DPS_Pct_Change'] = result_df.groupby('Ticker')['DPS'].pct_change()\n",
    "\n",
    "# Save dataset without direction columns\n",
    "result_df.to_csv('dividend_analysis_complete.csv', index=False)\n",
    "\n",
    "print(\"Complete dataset created!\")\n",
    "print(f\"Total rows: {len(result_df)}\")\n",
    "print(\"\\nColumns available:\")\n",
    "print(result_df.columns.tolist())\n",
    "print(f\"\\nDPS_Change statistics:\")\n",
    "print(result_df['DPS_Change'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50269778-edbc-4dd4-a10e-73013efcf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_change_df.to_csv('dividend_analysis_complete.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e0fcc-86a9-4dea-ab13-9658bd331e97",
   "metadata": {},
   "source": [
    "### Combined all independent variable and dependent for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2b1bd318-f556-427f-ac62-4027d578ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate columns removed!\n",
      "Final columns: ['Announcement_Date', 'Ticker', 'Dividend_Type', 'DPS', 'DPS_Change', 'DPS_Pct_Change', 'Dividend_Direction_Text', 'Dividend_Direction_Num', 'Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield', 'CAR']\n"
     ]
    }
   ],
   "source": [
    "# 1. Drop duplicate columns\n",
    "if 'Dividend_Direction' in regression_df.columns:\n",
    "    regression_df = regression_df.drop('Dividend_Direction', axis=1)\n",
    "\n",
    "# 2. Drop any FY_Year_x, FY_Year_y columns\n",
    "fy_columns_to_drop = ['FY_Year_x', 'FY_Year_y', 'FY_Year_mcap', 'ROA_FY_Year', 'MCap_FY_Year',  'Company_Name_x', 'Company_Name_y','Market_Cap_Cr_mcap', 'Log_Market_Cap_Cr','Market_Pct_Change']\n",
    "for col in fy_columns_to_drop:\n",
    "    if col in regression_df.columns:\n",
    "        regression_df = regression_df.drop(col, axis=1)\n",
    "\n",
    "# 3. Rename Relevant_FY_Year to FY_Year\n",
    "if 'Relevant_FY_Year' in regression_df.columns:\n",
    "    regression_df = regression_df.rename(columns={'Relevant_FY_Year': 'FY_Year'})\n",
    "\n",
    "# 4. Rearrange columns (simplified version)\n",
    "essential_columns = [\n",
    "    'Announcement_Date', 'Company_Name', 'Ticker', 'FY_Year', 'Dividend_Type',\n",
    "    'DPS', 'DPS_Change', 'DPS_Pct_Change', 'Dividend_Direction_Text', 'Dividend_Direction_Num',\n",
    "    'Event_Date_AdjClose', 'Prior_Day_AdjClose', 'Dividend_Yield',\n",
    "    'ROA', 'Market_Cap_Cr', 'CAR'\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "existing_columns = [col for col in essential_columns if col in regression_df.columns]\n",
    "other_columns = [col for col in regression_df.columns if col not in existing_columns]\n",
    "regression_df = regression_df[existing_columns + other_columns]\n",
    "\n",
    "# 5. Save clean dataset\n",
    "regression_df.to_csv('REGRESSION_DATASET.csv', index=False)\n",
    "\n",
    "print(\"Duplicate columns removed!\")\n",
    "print(\"Final columns:\", regression_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
